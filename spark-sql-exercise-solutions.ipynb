{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL mini project exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### README\n",
    "The exercises comes with this notebook, and a \"data\" folder. The data folder contains the dataset used for the exercises.\n",
    "Some of the code will be written to help you get started and some explanatory text to further aid the understanding of each exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is setting up a database and loading the dataset used for the exercises. This is already done berforehand. Just run all the cells until the **Exercise** part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-SNA9G3C:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2376ec50790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the spark session.\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Practise').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creates database\n",
    "spark.sql(\"CREATE DATABASE flightDB\")\n",
    "\n",
    "#Specifies which DB to use\n",
    "spark.sql(\"USE flightDB\")\n",
    "\n",
    "#Creates table\n",
    "spark.sql(\"\"\"\n",
    "            CREATE TABLE flights (\n",
    "            DEST_COUNTRY_NAME STRING COMMENT \"Describes destination country\", \n",
    "            ORIGIN_COUNTRY_NAME STRING COMMENT \"Describes departure country\", \n",
    "            count LONG COMMENT \"Describes number of departures\")\n",
    "            USING csv OPTIONS (header true, path 'C:/Users/Hecter/OneDrive/4. sem/Big Data Systems/Topic_1_Spark_Introduction/Kode/2015-summary.csv')\n",
    "            \"\"\")\n",
    "spark.sql(\"SELECT * FROM flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------------------+\n",
      "|           col_name|data_type|             comment|\n",
      "+-------------------+---------+--------------------+\n",
      "|  DEST_COUNTRY_NAME|   string|Describes destina...|\n",
      "|ORIGIN_COUNTRY_NAME|   string|Describes departu...|\n",
      "|              count|   bigint|Describes number ...|\n",
      "+-------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#METADATA\n",
    "spark.sql(\"DESCRIBE flights\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** From *flightDB* use the table *flights* to compute the number of flights for each destination country. Order this from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------------+\n",
      "|           Country|Number_of_arriving_flights|\n",
      "+------------------+--------------------------+\n",
      "|     United States|                    411352|\n",
      "|            Canada|                      8399|\n",
      "|            Mexico|                      7140|\n",
      "|    United Kingdom|                      2025|\n",
      "|             Japan|                      1548|\n",
      "|           Germany|                      1468|\n",
      "|Dominican Republic|                      1353|\n",
      "|       South Korea|                      1048|\n",
      "|       The Bahamas|                       955|\n",
      "|            France|                       935|\n",
      "|          Colombia|                       873|\n",
      "|            Brazil|                       853|\n",
      "|       Netherlands|                       776|\n",
      "|             China|                       772|\n",
      "|           Jamaica|                       666|\n",
      "|        Costa Rica|                       588|\n",
      "|       El Salvador|                       561|\n",
      "|            Panama|                       510|\n",
      "|              Cuba|                       466|\n",
      "|             Spain|                       420|\n",
      "+------------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE.\n",
    "\n",
    "# Number of flights for each destination country. Order this from highest to lowest.\n",
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME AS Country, sum(count) AS Number_of_arriving_flights FROM flights\n",
    "            GROUP BY Country \n",
    "            ORDER BY Number_of_arriving_flights DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Create a *view* that only contains countries of origen = 'United States' using the table *flights*.\n",
    "\n",
    "**TODO** Repeat the same process for exercise 1: compute the number of flights for each destination country. Order this from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+\n",
      "| DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+------------------+-------------------+------+\n",
      "|     United States|      United States|370002|\n",
      "|            Canada|      United States|  8399|\n",
      "|            Mexico|      United States|  7140|\n",
      "|    United Kingdom|      United States|  2025|\n",
      "|             Japan|      United States|  1548|\n",
      "|           Germany|      United States|  1468|\n",
      "|Dominican Republic|      United States|  1353|\n",
      "|       South Korea|      United States|  1048|\n",
      "|       The Bahamas|      United States|   955|\n",
      "|            France|      United States|   935|\n",
      "|          Colombia|      United States|   873|\n",
      "|            Brazil|      United States|   853|\n",
      "|       Netherlands|      United States|   776|\n",
      "|             China|      United States|   772|\n",
      "|           Jamaica|      United States|   666|\n",
      "|        Costa Rica|      United States|   588|\n",
      "|       El Salvador|      United States|   561|\n",
      "|            Panama|      United States|   510|\n",
      "|              Cuba|      United States|   466|\n",
      "|             Spain|      United States|   420|\n",
      "+------------------+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE.\n",
    "\n",
    "#Create a view displaying all departures from United States\n",
    "spark.sql(\"\"\"CREATE OR REPLACE VIEW dep_us AS \n",
    "            SELECT * FROM flights WHERE ORIGIN_COUNTRY_NAME = 'United States'\"\"\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM dep_us ORDER BY count DESC\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------------+\n",
      "|           Country|Number_of_arriving_flights|\n",
      "+------------------+--------------------------+\n",
      "|     United States|                    411352|\n",
      "|            Canada|                      8399|\n",
      "|            Mexico|                      7140|\n",
      "|    United Kingdom|                      2025|\n",
      "|             Japan|                      1548|\n",
      "|           Germany|                      1468|\n",
      "|Dominican Republic|                      1353|\n",
      "|       South Korea|                      1048|\n",
      "|       The Bahamas|                       955|\n",
      "|            France|                       935|\n",
      "|          Colombia|                       873|\n",
      "|            Brazil|                       853|\n",
      "|       Netherlands|                       776|\n",
      "|             China|                       772|\n",
      "|           Jamaica|                       666|\n",
      "|        Costa Rica|                       588|\n",
      "|       El Salvador|                       561|\n",
      "|            Panama|                       510|\n",
      "|              Cuba|                       466|\n",
      "|             Spain|                       420|\n",
      "+------------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Repeat the same process as in exercise 1 but this time with a view\n",
    "spark.sql(\"\"\"CREATE OR REPLACE VIEW all_dept AS\n",
    "            SELECT * FROM flights\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME AS Country, sum(count) AS Number_of_arriving_flights FROM all_dept\n",
    "            GROUP BY Country \n",
    "            ORDER BY Number_of_arriving_flights DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** In the sparkUI, determine how the results of exercise 1 and exercise 2 compares. Write with words your observations and explain them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: Execution was 91 ms by querying on a Table, however only 14 ms execution time on a View.\n",
    "The lower execution time is due to the data only being transformed in a View, whereas it is rewritten in a Table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Case statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Imagine your boss says the system is outdated. Every row containing the values 'United States' and 'Denmark' should be 'USA' and 'DK' respectively. And for mysterious reasons (the boss won't tell you) all other values should be 0 (for the country column).\n",
    "\n",
    "**NOTE** Use the table *partitioned_flights* to solve the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE.\n",
    "\n",
    "#Partitioned flights table\n",
    "spark.sql(\"\"\"\n",
    "            CREATE TABLE partitioned_flights USING parquet PARTITIONED BY (DEST_COUNTRY_NAME)\n",
    "            AS SELECT DEST_COUNTRY_NAME, count FROM flights LIMIT 10\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "|CASE WHEN (DEST_COUNTRY_NAME = United States) THEN USA WHEN (DEST_COUNTRY_NAME = Denmark) THEN DK ELSE NULL END|\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                            USA|\n",
      "|                                                                                                            USA|\n",
      "|                                                                                                            USA|\n",
      "|                                                                                                            USA|\n",
      "|                                                                                                            USA|\n",
      "|                                                                                                            USA|\n",
      "|                                                                                                           null|\n",
      "|                                                                                                           null|\n",
      "|                                                                                                           null|\n",
      "|                                                                                                           null|\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Case, when, then statement\n",
    "spark.sql(\"\"\"\n",
    "            SELECT \n",
    "            CASE WHEN DEST_COUNTRY_NAME = 'United States' then 'USA'\n",
    "            WHEN DEST_COUNTRY_NAME = 'Denmark' then 'DK'\n",
    "            ELSE NULL END\n",
    "            FROM partitioned_flights\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Convert an array into rows. The view *flights_agg* contains an array, use the created view to solve the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|col|   DEST_COUNTRY_NAME|\n",
      "+---+--------------------+\n",
      "|  4|             Algeria|\n",
      "| 15|              Angola|\n",
      "| 41|            Anguilla|\n",
      "|126| Antigua and Barbuda|\n",
      "|180|           Argentina|\n",
      "|346|               Aruba|\n",
      "|329|           Australia|\n",
      "| 62|             Austria|\n",
      "| 21|          Azerbaijan|\n",
      "| 19|             Bahrain|\n",
      "|154|            Barbados|\n",
      "|259|             Belgium|\n",
      "|188|              Belize|\n",
      "|183|             Bermuda|\n",
      "| 30|             Bolivia|\n",
      "| 58|Bonaire, Sint Eus...|\n",
      "|853|              Brazil|\n",
      "|107|British Virgin Is...|\n",
      "|  3|            Bulgaria|\n",
      "|  1|        Burkina Faso|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE.\n",
    "\n",
    "#Create flights_agg view\n",
    "spark.sql(\"\"\"\n",
    "            CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "            SELECT DEST_COUNTRY_NAME, collect_set(count) as collected_counts\n",
    "            FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "            \"\"\")\n",
    "\n",
    "# Convert an array into rows\n",
    "spark.sql(\"\"\"SELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: User defined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Create a function that determines the ratio between how many departures and arrivals each country has. **NOTE** Create a view, based on the table *flights*, containing the information needed to compute the ratio.\n",
    "\n",
    "**TODO** Create a pandas function that also calculates the ratio using the package *pandas_udf*. Is there a performance difference? Describe your answer and explain. **NOTE** The required packages are pre imported and no further packages should be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES FOR DEVELOPERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE VIEW IF NOT EXISTS nested_data AS \n",
    "SELECT (DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME) as country, count FROM flights\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             country|count|\n",
      "+--------------------+-----+\n",
      "|{United States, R...|   15|\n",
      "|{United States, C...|    1|\n",
      "|{United States, I...|  344|\n",
      "|{Egypt, United St...|   15|\n",
      "|{United States, I...|   62|\n",
      "|{United States, S...|    1|\n",
      "|{United States, G...|   62|\n",
      "|{Costa Rica, Unit...|  588|\n",
      "|{Senegal, United ...|   40|\n",
      "|{Moldova, United ...|    1|\n",
      "|{United States, S...|  325|\n",
      "|{United States, M...|   39|\n",
      "|{Guyana, United S...|   64|\n",
      "|{Malta, United St...|    1|\n",
      "|{Anguilla, United...|   41|\n",
      "|{Bolivia, United ...|   30|\n",
      "|{United States, P...|    6|\n",
      "|{Algeria, United ...|    4|\n",
      "|{Turks and Caicos...|  230|\n",
      "|{United States, G...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM nested_data\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+\n",
      "|            new_name|flight_counts|     origin_set|\n",
      "+--------------------+-------------+---------------+\n",
      "|             Algeria|          [4]|[United States]|\n",
      "|              Angola|         [15]|[United States]|\n",
      "|            Anguilla|         [41]|[United States]|\n",
      "| Antigua and Barbuda|        [126]|[United States]|\n",
      "|           Argentina|        [180]|[United States]|\n",
      "|               Aruba|        [346]|[United States]|\n",
      "|           Australia|        [329]|[United States]|\n",
      "|             Austria|         [62]|[United States]|\n",
      "|          Azerbaijan|         [21]|[United States]|\n",
      "|             Bahrain|         [19]|[United States]|\n",
      "|            Barbados|        [154]|[United States]|\n",
      "|             Belgium|        [259]|[United States]|\n",
      "|              Belize|        [188]|[United States]|\n",
      "|             Bermuda|        [183]|[United States]|\n",
      "|             Bolivia|         [30]|[United States]|\n",
      "|Bonaire, Sint Eus...|         [58]|[United States]|\n",
      "|              Brazil|        [853]|[United States]|\n",
      "|British Virgin Is...|        [107]|[United States]|\n",
      "|            Bulgaria|          [3]|[United States]|\n",
      "|        Burkina Faso|          [1]|[United States]|\n",
      "+--------------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME as new_name, collect_set(count) as flight_counts,\n",
    "collect_set(ORIGIN_COUNTRY_NAME) as origin_set\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|   DEST_COUNTRY_NAME|array(1, 2, 3)|\n",
      "+--------------------+--------------+\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|               Egypt|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|          Costa Rica|     [1, 2, 3]|\n",
      "|             Senegal|     [1, 2, 3]|\n",
      "|             Moldova|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|              Guyana|     [1, 2, 3]|\n",
      "|               Malta|     [1, 2, 3]|\n",
      "|            Anguilla|     [1, 2, 3]|\n",
      "|             Bolivia|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|             Algeria|     [1, 2, 3]|\n",
      "|Turks and Caicos ...|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3) FROM flights\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|            new_name|collect_list(count)[0]|\n",
      "+--------------------+----------------------+\n",
      "|             Algeria|                     4|\n",
      "|              Angola|                    15|\n",
      "|            Anguilla|                    41|\n",
      "| Antigua and Barbuda|                   126|\n",
      "|           Argentina|                   180|\n",
      "|               Aruba|                   346|\n",
      "|           Australia|                   329|\n",
      "|             Austria|                    62|\n",
      "|          Azerbaijan|                    21|\n",
      "|             Bahrain|                    19|\n",
      "|            Barbados|                   154|\n",
      "|             Belgium|                   259|\n",
      "|              Belize|                   188|\n",
      "|             Bermuda|                   183|\n",
      "|             Bolivia|                    30|\n",
      "|Bonaire, Sint Eus...|                    58|\n",
      "|              Brazil|                   853|\n",
      "|British Virgin Is...|                   107|\n",
      "|            Bulgaria|                     3|\n",
      "|        Burkina Faso|                     1|\n",
      "+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME as new_name, collect_list(count)[0]\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "SELECT DEST_COUNTRY_NAME, collect_set(count) as collected_counts\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|col|   DEST_COUNTRY_NAME|\n",
      "+---+--------------------+\n",
      "|  4|             Algeria|\n",
      "| 15|              Angola|\n",
      "| 41|            Anguilla|\n",
      "|126| Antigua and Barbuda|\n",
      "|180|           Argentina|\n",
      "|346|               Aruba|\n",
      "|329|           Australia|\n",
      "| 62|             Austria|\n",
      "| 21|          Azerbaijan|\n",
      "| 19|             Bahrain|\n",
      "|154|            Barbados|\n",
      "|259|             Belgium|\n",
      "|188|              Belize|\n",
      "|183|             Bermuda|\n",
      "| 30|             Bolivia|\n",
      "| 58|Bonaire, Sint Eus...|\n",
      "|853|              Brazil|\n",
      "|107|British Virgin Is...|\n",
      "|  3|            Bulgaria|\n",
      "|  1|        Burkina Faso|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Egypt|      United States|   15|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  382|\n",
      "|            Pakistan|      United States|   12|\n",
      "|             Iceland|      United States|  181|\n",
      "|    Marshall Islands|      United States|   42|\n",
      "|          Luxembourg|      United States|  155|\n",
      "|            Honduras|      United States|  362|\n",
      "|         The Bahamas|      United States|  955|\n",
      "|         El Salvador|      United States|  561|\n",
      "|               Samoa|      United States|   25|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM flights\n",
    "WHERE origin_country_name IN (SELECT dest_country_name FROM flights\n",
    "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping the table and database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS flights\")\n",
    "#spark.sql(\"DROP DATABASE IF EXISTS flightDB\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2173472595553774291f7a41b22ecde918eb4c64316514c73849b879da0cd995"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL mini project exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### README\n",
    "The exercises comes with this notebook, and a \"data\" folder. The data folder contains the dataset used for the exercises.\n",
    "Some of the code will be written to help you get started and some explanatory text to further aid the understanding of each exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is setting up a database and loading the dataset used for the exercises. This is already done berforehand. Just run all the cells until the **Exercise** part.\n",
    "\n",
    "**However**, note the path used to read the dataset from the *'data'* folder. This path works for unix based systems, but for windows users this *might* result in conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/19 17:30:59 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.50.144 instead (on interface wlp4s0)\n",
      "22/02/19 17:30:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/vugs/Environments/webscraping/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/19 17:31:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/02/19 17:31:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.50.144:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4e75d5edc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the spark session.\n",
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path.cwd() / 'data'\n",
    "\n",
    "spark=SparkSession.builder.appName('Practise').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creates database\n",
    "spark.sql(\"CREATE DATABASE flightDB\")\n",
    "\n",
    "#Specifies which DB to use\n",
    "spark.sql(\"USE flightDB\")\n",
    "\n",
    "#Creates table\n",
    "spark.sql(f\"\"\"\n",
    "            CREATE TABLE flights (\n",
    "            DEST_COUNTRY_NAME STRING COMMENT \"Describes destination country\", \n",
    "            ORIGIN_COUNTRY_NAME STRING COMMENT \"Describes departure country\", \n",
    "            count LONG COMMENT \"Describes number of departures\")\n",
    "            USING csv OPTIONS (header true, path '{data_path}')\n",
    "            \"\"\")\n",
    "spark.sql(\"SELECT * FROM flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------------------+\n",
      "|           col_name|data_type|             comment|\n",
      "+-------------------+---------+--------------------+\n",
      "|  DEST_COUNTRY_NAME|   string|Describes destina...|\n",
      "|ORIGIN_COUNTRY_NAME|   string|Describes departu...|\n",
      "|              count|   bigint|Describes number ...|\n",
      "+-------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#METADATA\n",
    "spark.sql(\"DESCRIBE flights\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** From *flightDB* use the table *flights* to compute the number of flights for each destination country. Order this from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------------+\n",
      "|           Country|Number_of_arriving_flights|\n",
      "+------------------+--------------------------+\n",
      "|     United States|                   6581632|\n",
      "|            Canada|                    134384|\n",
      "|            Mexico|                    114240|\n",
      "|    United Kingdom|                     32400|\n",
      "|             Japan|                     24768|\n",
      "|           Germany|                     23488|\n",
      "|Dominican Republic|                     21648|\n",
      "|       South Korea|                     16768|\n",
      "|       The Bahamas|                     15280|\n",
      "|            France|                     14960|\n",
      "|          Colombia|                     13968|\n",
      "|            Brazil|                     13648|\n",
      "|       Netherlands|                     12416|\n",
      "|             China|                     12352|\n",
      "|           Jamaica|                     10656|\n",
      "|        Costa Rica|                      9408|\n",
      "|       El Salvador|                      8976|\n",
      "|            Panama|                      8160|\n",
      "|              Cuba|                      7456|\n",
      "|             Spain|                      6720|\n",
      "+------------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of flights for each destination country. Order this from highest to lowest.\n",
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME AS Country, sum(count) AS Number_of_arriving_flights FROM flights\n",
    "            GROUP BY Country \n",
    "            ORDER BY Number_of_arriving_flights DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Create a *view* using the table *flights* (include all rows and columns).\n",
    "\n",
    "**TODO** Repeat the same process for exercise 1: compute the number of flights for each destination country. Order this from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------------+\n",
      "|           Country|Number_of_arriving_flights|\n",
      "+------------------+--------------------------+\n",
      "|     United States|                   6581632|\n",
      "|            Canada|                    134384|\n",
      "|            Mexico|                    114240|\n",
      "|    United Kingdom|                     32400|\n",
      "|             Japan|                     24768|\n",
      "|           Germany|                     23488|\n",
      "|Dominican Republic|                     21648|\n",
      "|       South Korea|                     16768|\n",
      "|       The Bahamas|                     15280|\n",
      "|            France|                     14960|\n",
      "|          Colombia|                     13968|\n",
      "|            Brazil|                     13648|\n",
      "|       Netherlands|                     12416|\n",
      "|             China|                     12352|\n",
      "|           Jamaica|                     10656|\n",
      "|        Costa Rica|                      9408|\n",
      "|       El Salvador|                      8976|\n",
      "|            Panama|                      8160|\n",
      "|              Cuba|                      7456|\n",
      "|             Spain|                      6720|\n",
      "+------------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Repeat the same process as in exercise 1 but this time with a view\n",
    "spark.sql(\"\"\"CREATE OR REPLACE VIEW all_dept AS\n",
    "            SELECT * FROM flights\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME AS Country, sum(count) AS Number_of_arriving_flights FROM all_dept\n",
    "            GROUP BY Country \n",
    "            ORDER BY Number_of_arriving_flights DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** In the sparkUI, determine how the results of exercise 1 and exercise 2 compares. Write with words your observations and explain them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: Execution was 91 ms by querying on a Table, however only 14 ms execution time on a View.\n",
    "The lower execution time is due to the data only being transformed in a View, whereas it is rewritten in a Table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Case statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Imagine your boss says the system is outdated. Every row containing the values 'United States' and 'Denmark' should be 'USA' and 'DK' respectively. And for mysterious reasons (the boss won't tell you) all other values should be 0 (for the country column).\n",
    "\n",
    "**NOTE** Use the table *partitioned_flights* to solve the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------+\n",
      "|CASE WHEN (DEST_COUNTRY_NAME = United States) THEN USA WHEN (DEST_COUNTRY_NAME = Denmark) THEN DK ELSE 0 END|\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                         USA|\n",
      "|                                                                                                         USA|\n",
      "|                                                                                                         USA|\n",
      "|                                                                                                         USA|\n",
      "|                                                                                                         USA|\n",
      "|                                                                                                         USA|\n",
      "|                                                                                                           0|\n",
      "|                                                                                                           0|\n",
      "|                                                                                                           0|\n",
      "|                                                                                                           0|\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Partitioned flights table\n",
    "spark.sql(\"\"\"\n",
    "            CREATE TABLE partitioned_flights USING parquet PARTITIONED BY (DEST_COUNTRY_NAME)\n",
    "            AS SELECT DEST_COUNTRY_NAME, count FROM flights LIMIT 10\n",
    "            \"\"\")\n",
    "\n",
    "#Case, when, then statement\n",
    "spark.sql(\"\"\"\n",
    "            SELECT \n",
    "            CASE WHEN DEST_COUNTRY_NAME = 'United States' then 'USA'\n",
    "            WHEN DEST_COUNTRY_NAME = 'Denmark' then 'DK'\n",
    "            ELSE 0 END\n",
    "            FROM partitioned_flights\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Convert an array into rows. The view *flights_agg* contains an array, use the created view to solve the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|col|   DEST_COUNTRY_NAME|\n",
      "+---+--------------------+\n",
      "|  4|             Algeria|\n",
      "| 15|              Angola|\n",
      "| 41|            Anguilla|\n",
      "|126| Antigua and Barbuda|\n",
      "|180|           Argentina|\n",
      "|346|               Aruba|\n",
      "|329|           Australia|\n",
      "| 62|             Austria|\n",
      "| 21|          Azerbaijan|\n",
      "| 19|             Bahrain|\n",
      "|154|            Barbados|\n",
      "|259|             Belgium|\n",
      "|188|              Belize|\n",
      "|183|             Bermuda|\n",
      "| 30|             Bolivia|\n",
      "| 58|Bonaire, Sint Eus...|\n",
      "|853|              Brazil|\n",
      "|107|British Virgin Is...|\n",
      "|  3|            Bulgaria|\n",
      "|  1|        Burkina Faso|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create flights_agg view\n",
    "spark.sql(\"\"\"\n",
    "            CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "            SELECT DEST_COUNTRY_NAME, collect_set(count) as collected_counts\n",
    "            FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "            \"\"\")\n",
    "\n",
    "# Convert an array into rows\n",
    "spark.sql(\"\"\"SELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: User defined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Create a function that determines the ratio between how many departures and arrivals each country has. **NOTE** Create a view, based on the table *flights*, containing the information needed to compute the ratio.\n",
    "\n",
    "**TODO** Create a pandas function that also calculates the ratio using the package *pandas_udf*. Is there a performance difference? Describe your answer and explain. **NOTE** The required packages are pre imported and no further packages should be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|function|\n",
      "+--------+\n",
      "|       !|\n",
      "|      !=|\n",
      "|       %|\n",
      "|       &|\n",
      "|       *|\n",
      "|       +|\n",
      "|       -|\n",
      "|       /|\n",
      "|       <|\n",
      "|      <=|\n",
      "|     <=>|\n",
      "|      <>|\n",
      "|       =|\n",
      "|      ==|\n",
      "|       >|\n",
      "|      >=|\n",
      "|       ^|\n",
      "|     abs|\n",
      "|    acos|\n",
      "|   acosh|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# Prints a list of all functions.\n",
    "spark.sql(\"\"\"SHOW FUNCTIONS\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|function|\n",
      "+--------+\n",
      "|       !|\n",
      "|      !=|\n",
      "|       %|\n",
      "|       &|\n",
      "|       *|\n",
      "|       +|\n",
      "|       -|\n",
      "|       /|\n",
      "|       <|\n",
      "|      <=|\n",
      "|     <=>|\n",
      "|      <>|\n",
      "|       =|\n",
      "|      ==|\n",
      "|       >|\n",
      "|      >=|\n",
      "|       ^|\n",
      "|     abs|\n",
      "|    acos|\n",
      "|   acosh|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prints a list of only system functions.\n",
    "spark.sql(\"\"\"SHOW SYSTEM FUNCTIONS\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|           function|\n",
      "+-------------------+\n",
      "|       flight_ratio|\n",
      "|pandas_flight_ratio|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prints a list of only user defined functions.\n",
    "spark.sql(\"\"\"SHOW USER FUNCTIONS\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/19 18:46:58 WARN SimpleFunctionRegistry: The function flight_ratio replaced a previously registered function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+----------+\n",
      "|             COUNTRY|ARRIVALS|DEPARTURES|     RATIO|\n",
      "+--------------------+--------+----------+----------+\n",
      "|            Paraguay|     960|        96|      10.0|\n",
      "|              Russia|    2816|      2576| 1.0931677|\n",
      "|            Anguilla|     656|       608| 1.0789474|\n",
      "|             Senegal|     640|       672|0.95238096|\n",
      "|              Sweden|    1888|      1904|0.99159664|\n",
      "|            Kiribati|     416|       560|0.74285716|\n",
      "|              Guyana|    1024|      1008| 1.0158731|\n",
      "|         Philippines|    2144|      2016| 1.0634921|\n",
      "|           Singapore|      48|        16|       3.0|\n",
      "|            Malaysia|      32|        48| 0.6666667|\n",
      "|                Fiji|     384|       400|      0.96|\n",
      "|              Turkey|    2208|      2064| 1.0697675|\n",
      "|             Germany|   23488|     21376| 1.0988024|\n",
      "|              Jordan|     704|       704|       1.0|\n",
      "|               Palau|     480|       496| 0.9677419|\n",
      "|Turks and Caicos ...|    3680|      3776| 0.9745763|\n",
      "|              France|   14960|     15232|0.98214287|\n",
      "|              Greece|     480|       368| 1.3043479|\n",
      "|British Virgin Is...|    1712|      1280|    1.3375|\n",
      "|              Taiwan|    4256|      3760| 1.1319149|\n",
      "+--------------------+--------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            CREATE OR REPLACE TEMP VIEW arrivals AS\n",
    "            SELECT DEST_COUNTRY_NAME as ARRIVAL_COUNTRY, sum(count) as ARRIVALS FROM flights \n",
    "            GROUP BY ARRIVAL_COUNTRY\n",
    "            \"\"\")\n",
    "spark.sql(\"\"\"\n",
    "            CREATE OR REPLACE TEMP VIEW departures AS\n",
    "            SELECT ORIGIN_COUNTRY_NAME as DEPARTURE_COUNTRY, sum(count) as DEPARTURES FROM flights \n",
    "            GROUP BY DEPARTURE_COUNTRY\n",
    "            \"\"\")\n",
    "def flight_ratio(arrival, departure):\n",
    "    return arrival/departure\n",
    "\n",
    "spark.udf.register(\"flight_ratio\", flight_ratio, FloatType())\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "            SELECT arrivals.ARRIVAL_COUNTRY AS COUNTRY, arrivals.ARRIVALS, departures.DEPARTURES, flight_ratio(arrivals.ARRIVALS, departures.DEPARTURES) AS RATIO\n",
    "            FROM arrivals\n",
    "            RIGHT JOIN departures\n",
    "            ON arrivals.ARRIVAL_COUNTRY = departures.DEPARTURE_COUNTRY\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/19 18:47:02 WARN SimpleFunctionRegistry: The function pandas_flight_ratio replaced a previously registered function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+----------+\n",
      "|             COUNTRY|ARRIVALS|DEPARTURES|     RATIO|\n",
      "+--------------------+--------+----------+----------+\n",
      "|            Paraguay|     960|        96|      10.0|\n",
      "|              Russia|    2816|      2576| 1.0931677|\n",
      "|            Anguilla|     656|       608| 1.0789474|\n",
      "|             Senegal|     640|       672|0.95238096|\n",
      "|              Sweden|    1888|      1904|0.99159664|\n",
      "|            Kiribati|     416|       560|0.74285716|\n",
      "|              Guyana|    1024|      1008| 1.0158731|\n",
      "|         Philippines|    2144|      2016| 1.0634921|\n",
      "|           Singapore|      48|        16|       3.0|\n",
      "|            Malaysia|      32|        48| 0.6666667|\n",
      "|                Fiji|     384|       400|      0.96|\n",
      "|              Turkey|    2208|      2064| 1.0697675|\n",
      "|             Germany|   23488|     21376| 1.0988024|\n",
      "|              Jordan|     704|       704|       1.0|\n",
      "|               Palau|     480|       496| 0.9677419|\n",
      "|Turks and Caicos ...|    3680|      3776| 0.9745763|\n",
      "|              France|   14960|     15232|0.98214287|\n",
      "|              Greece|     480|       368| 1.3043479|\n",
      "|British Virgin Is...|    1712|      1280|    1.3375|\n",
      "|              Taiwan|    4256|      3760| 1.1319149|\n",
      "+--------------------+--------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pandas Solution\n",
    "#!pip install pyarrow\n",
    "\n",
    "# The function\n",
    "def flight_ratio(arrivals: pd.Series, departures: pd.Series) -> pd.Series:\n",
    "    return arrivals/departures\n",
    "\n",
    "# Create the pandas UDF for the flight_ratio function\n",
    "pandas_flight_ratio = pandas_udf(flight_ratio, returnType=FloatType())\n",
    "\n",
    "# Register the function\n",
    "spark.udf.register(\"pandas_flight_ratio\", pandas_flight_ratio)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "            SELECT arrivals.ARRIVAL_COUNTRY AS COUNTRY, arrivals.ARRIVALS, departures.DEPARTURES, pandas_flight_ratio(arrivals.ARRIVALS, departures.DEPARTURES) AS RATIO\n",
    "            FROM arrivals\n",
    "            RIGHT JOIN departures\n",
    "            ON arrivals.ARRIVAL_COUNTRY = departures.DEPARTURE_COUNTRY\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping the table and database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS flights\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS partitioned_flights\")\n",
    "spark.sql(\"DROP DATABASE IF EXISTS flightDB\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2173472595553774291f7a41b22ecde918eb4c64316514c73849b879da0cd995"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

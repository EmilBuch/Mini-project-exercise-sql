{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL mini project exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### README\n",
    "The exercises comes with this notebook, and a \"data\" folder. The data folder contains the dataset used for the exercises.\n",
    "Some of the code will be written to help you get started and some explanatory text to further aid the understanding of each exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is setting up a database and loading the dataset used for the exercises. This is already done berforehand. Just run all the cells until the **Exercise** part.\n",
    "\n",
    "**However**, note the path used to read the dataset from the *'data'* folder. This path works for unix based systems, but for windows users this *might* result in conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/17 18:24:54 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.50.144 instead (on interface wlp4s0)\n",
      "22/02/17 18:24:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/vugs/Environments/webscraping/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/17 18:24:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.50.144:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc5242fe460>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the spark session.\n",
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path.cwd() / 'data'\n",
    "\n",
    "spark=SparkSession.builder.appName('Practise').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creates database\n",
    "spark.sql(\"CREATE DATABASE flightDB\")\n",
    "\n",
    "#Specifies which DB to use\n",
    "spark.sql(\"USE flightDB\")\n",
    "\n",
    "#Creates table\n",
    "spark.sql(f\"\"\"\n",
    "            CREATE TABLE flights (\n",
    "            DEST_COUNTRY_NAME STRING COMMENT \"Describes destination country\", \n",
    "            ORIGIN_COUNTRY_NAME STRING COMMENT \"Describes departure country\", \n",
    "            count LONG COMMENT \"Describes number of departures\")\n",
    "            USING csv OPTIONS (header true, path '{data_path}')\n",
    "            \"\"\")\n",
    "spark.sql(\"SELECT * FROM flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------------------+\n",
      "|           col_name|data_type|             comment|\n",
      "+-------------------+---------+--------------------+\n",
      "|  DEST_COUNTRY_NAME|   string|Describes destina...|\n",
      "|ORIGIN_COUNTRY_NAME|   string|Describes departu...|\n",
      "|              count|   bigint|Describes number ...|\n",
      "+-------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#METADATA\n",
    "spark.sql(\"DESCRIBE flights\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** From *flightDB* use the table *flights* to compute the number of flights for each destination country. Order this from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Create a *view* that only contains countries of origen = 'United States' using the table *flights*.\n",
    "\n",
    "**TODO** Repeat the same process for exercise 1: compute the number of flights for each destination country. Order this from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE.\n",
    "\n",
    "#Create a view displaying all departures from United States\n",
    "spark.sql(\"\"\"CREATE OR REPLACE VIEW dep_us AS \n",
    "            SELECT * FROM flights WHERE ORIGIN_COUNTRY_NAME = 'United States'\"\"\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM dep_us ORDER BY count DESC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** In the sparkUI, determine how the results of exercise 1 and exercise 2 compares. Write with words your observations and explain them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answers here for exercise 3..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Case statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Imagine your boss says the system is outdated. Every row containing the values 'United States' and 'Denmark' should be 'USA' and 'DK' respectively. And for mysterious reasons (the boss won't tell you) all other values should be 0 (for the country column).\n",
    "\n",
    "**NOTE** Use the table *partitioned_flights* to solve the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE.\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "            CREATE TABLE partitioned_flights USING parquet PARTITIONED BY (DEST_COUNTRY_NAME)\n",
    "            AS SELECT DEST_COUNTRY_NAME, count FROM flights LIMIT 5\n",
    "            \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Convert an array into rows. The view *flights_agg* contains an array, use the created view to solve the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEVELOPERS. WRITE THE CORRECT SOLUTION HERE.\n",
    "spark.sql(\"\"\"\n",
    "            CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "            SELECT DEST_COUNTRY_NAME, collect_set(count) as collected_counts\n",
    "            FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "            \"\"\")\n",
    "spark.sql(\"\"\"SELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: User defined functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Create a function that determines the ratio between how many departures and arrivals each country has. **NOTE** Create a view, based on the table *flights*, containing the information needed to compute the ratio.\n",
    "\n",
    "**TODO** Create a pandas function that also calculates the ratio using the package *pandas_udf*. Is there a performance difference? Describe your answer and explain. **NOTE** The required packages are pre imported and no further packages should be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "# Prints a list of all functions.\n",
    "spark.sql(\"\"\"SHOW FUNCTIONS\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints a list of only system functions.\n",
    "spark.sql(\"\"\"SHOW SYSTEM FUNCTIONS\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints a list of only user defined functions.\n",
    "spark.sql(\"\"\"SHOW USER FUNCTIONS\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution to exercise 6 here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES FOR DEVELOPERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE VIEW IF NOT EXISTS nested_data AS \n",
    "SELECT (DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME) as country, count FROM flights\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             country|count|\n",
      "+--------------------+-----+\n",
      "|{United States, R...|   15|\n",
      "|{United States, C...|    1|\n",
      "|{United States, I...|  344|\n",
      "|{Egypt, United St...|   15|\n",
      "|{United States, I...|   62|\n",
      "|{United States, S...|    1|\n",
      "|{United States, G...|   62|\n",
      "|{Costa Rica, Unit...|  588|\n",
      "|{Senegal, United ...|   40|\n",
      "|{Moldova, United ...|    1|\n",
      "|{United States, S...|  325|\n",
      "|{United States, M...|   39|\n",
      "|{Guyana, United S...|   64|\n",
      "|{Malta, United St...|    1|\n",
      "|{Anguilla, United...|   41|\n",
      "|{Bolivia, United ...|   30|\n",
      "|{United States, P...|    6|\n",
      "|{Algeria, United ...|    4|\n",
      "|{Turks and Caicos...|  230|\n",
      "|{United States, G...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM nested_data\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+\n",
      "|            new_name|flight_counts|     origin_set|\n",
      "+--------------------+-------------+---------------+\n",
      "|             Algeria|          [4]|[United States]|\n",
      "|              Angola|         [15]|[United States]|\n",
      "|            Anguilla|         [41]|[United States]|\n",
      "| Antigua and Barbuda|        [126]|[United States]|\n",
      "|           Argentina|        [180]|[United States]|\n",
      "|               Aruba|        [346]|[United States]|\n",
      "|           Australia|        [329]|[United States]|\n",
      "|             Austria|         [62]|[United States]|\n",
      "|          Azerbaijan|         [21]|[United States]|\n",
      "|             Bahrain|         [19]|[United States]|\n",
      "|            Barbados|        [154]|[United States]|\n",
      "|             Belgium|        [259]|[United States]|\n",
      "|              Belize|        [188]|[United States]|\n",
      "|             Bermuda|        [183]|[United States]|\n",
      "|             Bolivia|         [30]|[United States]|\n",
      "|Bonaire, Sint Eus...|         [58]|[United States]|\n",
      "|              Brazil|        [853]|[United States]|\n",
      "|British Virgin Is...|        [107]|[United States]|\n",
      "|            Bulgaria|          [3]|[United States]|\n",
      "|        Burkina Faso|          [1]|[United States]|\n",
      "+--------------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME as new_name, collect_set(count) as flight_counts,\n",
    "collect_set(ORIGIN_COUNTRY_NAME) as origin_set\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|   DEST_COUNTRY_NAME|array(1, 2, 3)|\n",
      "+--------------------+--------------+\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|               Egypt|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|          Costa Rica|     [1, 2, 3]|\n",
      "|             Senegal|     [1, 2, 3]|\n",
      "|             Moldova|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|              Guyana|     [1, 2, 3]|\n",
      "|               Malta|     [1, 2, 3]|\n",
      "|            Anguilla|     [1, 2, 3]|\n",
      "|             Bolivia|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|             Algeria|     [1, 2, 3]|\n",
      "|Turks and Caicos ...|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3) FROM flights\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|            new_name|collect_list(count)[0]|\n",
      "+--------------------+----------------------+\n",
      "|             Algeria|                     4|\n",
      "|              Angola|                    15|\n",
      "|            Anguilla|                    41|\n",
      "| Antigua and Barbuda|                   126|\n",
      "|           Argentina|                   180|\n",
      "|               Aruba|                   346|\n",
      "|           Australia|                   329|\n",
      "|             Austria|                    62|\n",
      "|          Azerbaijan|                    21|\n",
      "|             Bahrain|                    19|\n",
      "|            Barbados|                   154|\n",
      "|             Belgium|                   259|\n",
      "|              Belize|                   188|\n",
      "|             Bermuda|                   183|\n",
      "|             Bolivia|                    30|\n",
      "|Bonaire, Sint Eus...|                    58|\n",
      "|              Brazil|                   853|\n",
      "|British Virgin Is...|                   107|\n",
      "|            Bulgaria|                     3|\n",
      "|        Burkina Faso|                     1|\n",
      "+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME as new_name, collect_list(count)[0]\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "SELECT DEST_COUNTRY_NAME, collect_set(count) as collected_counts\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|col|   DEST_COUNTRY_NAME|\n",
      "+---+--------------------+\n",
      "|  4|             Algeria|\n",
      "| 15|              Angola|\n",
      "| 41|            Anguilla|\n",
      "|126| Antigua and Barbuda|\n",
      "|180|           Argentina|\n",
      "|346|               Aruba|\n",
      "|329|           Australia|\n",
      "| 62|             Austria|\n",
      "| 21|          Azerbaijan|\n",
      "| 19|             Bahrain|\n",
      "|154|            Barbados|\n",
      "|259|             Belgium|\n",
      "|188|              Belize|\n",
      "|183|             Bermuda|\n",
      "| 30|             Bolivia|\n",
      "| 58|Bonaire, Sint Eus...|\n",
      "|853|              Brazil|\n",
      "|107|British Virgin Is...|\n",
      "|  3|            Bulgaria|\n",
      "|  1|        Burkina Faso|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Egypt|      United States|   15|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  382|\n",
      "|            Pakistan|      United States|   12|\n",
      "|             Iceland|      United States|  181|\n",
      "|    Marshall Islands|      United States|   42|\n",
      "|          Luxembourg|      United States|  155|\n",
      "|            Honduras|      United States|  362|\n",
      "|         The Bahamas|      United States|  955|\n",
      "|         El Salvador|      United States|  561|\n",
      "|               Samoa|      United States|   25|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM flights\n",
    "WHERE origin_country_name IN (SELECT dest_country_name FROM flights\n",
    "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping the table and database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS flights\")\n",
    "spark.sql(\"DROP DATABASE IF EXISTS flightDB\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2173472595553774291f7a41b22ecde918eb4c64316514c73849b879da0cd995"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
